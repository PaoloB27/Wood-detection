{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-j9lmF1HsEm"
      },
      "source": [
        "# Import and drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot3Gg-8lVYea"
      },
      "source": [
        "Import statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C3d8FW7AVaoI"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5doUewLQZlXU"
      },
      "source": [
        "Mount the drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG9ThHhhZqZN",
        "outputId": "5b5f2258-94a0-4a39-dc53-0d3968a1a895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/Colab_environments/WoodClassification\n"
          ]
        }
      ],
      "source": [
        "# mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "# enter the desired folder\n",
        "%cd drive/MyDrive/Colab_environments/WoodClassification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbUZtmgoa5A9"
      },
      "source": [
        "Unzip the training folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T5_UrjD1bWtB"
      },
      "outputs": [],
      "source": [
        "# with zipfile.ZipFile(os.path.join(os.getcwd(), \"TRAINING.zip\"), 'r') as zip_ref:\n",
        "#      zip_ref.extractall(os.path.join(os.getcwd(), \"TRAINING\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdrWO2wZR7Kz"
      },
      "source": [
        "Set the device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DuihdjfGR6Qr"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03-7YfO3bDAy"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ig9_psyLbGmA"
      },
      "outputs": [],
      "source": [
        "# Loads a .tiff image using PIL.\n",
        "# image_path: path to the image to be loaded.\n",
        "# Returns an image with mode \"L\".\n",
        "def load_image(image_path):\n",
        "\n",
        "    # load the image with PIL\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # convert it into a numpy array\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # max pixel value\n",
        "    max_val = np.max(image_np)\n",
        "\n",
        "    # new desired max value\n",
        "    new_max_val = 255\n",
        "\n",
        "    # normalize the pixels and convert their values into unsigned integers\n",
        "    normalized_image = (image_np / max_val * new_max_val).astype(np.uint8)\n",
        "\n",
        "    # return the greyscale image represented by the numpy array\n",
        "    return Image.fromarray(normalized_image, mode=\"L\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dp7-Z9IybRON"
      },
      "outputs": [],
      "source": [
        "# Function to compute the mean pixel value of images in folder_path.\n",
        "# folder_path: path to the folder containing images.\n",
        "# device: device to be used for the computation.\n",
        "# Returns the mean value of pixels of images in folder_path.\n",
        "def compute_mean(folder_path, device):\n",
        "\n",
        "    # initialize the mean and the number of images\n",
        "    mean = torch.tensor(0.0, device=device)\n",
        "    n_images = torch.tensor(0, device=device)\n",
        "\n",
        "    # iterate over each class folder\n",
        "    for sub_dir_name in os.listdir(folder_path):\n",
        "\n",
        "        # current sub directory\n",
        "        curr_sub_dir = os.path.join(folder_path, sub_dir_name)\n",
        "\n",
        "        # add to samples each tuple for the current class\n",
        "        for file_name in os.listdir(curr_sub_dir):\n",
        "\n",
        "            if file_name.endswith(\".tiff\"):\n",
        "\n",
        "                # load the current image\n",
        "                image = load_image(os.path.join(curr_sub_dir, file_name))\n",
        "\n",
        "                # apply some other requested transformations\n",
        "                transformations = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "                image = transformations(image).to(device)\n",
        "\n",
        "                # update the mean and the number of images\n",
        "                mean += image.mean()\n",
        "                n_images += 1\n",
        "\n",
        "    # return the mean over all images in the dataset\n",
        "    return mean / n_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jFBum6otbRjD"
      },
      "outputs": [],
      "source": [
        "# Function to compute the standard deviation of pixels of images in folder_path.\n",
        "# folder_path: path to the folder containing images.\n",
        "# device: device to be used for the computation.\n",
        "# Returns the standard deviation of pixels of images in folder_path.\n",
        "def compute_std(folder_path, mean, device):\n",
        "\n",
        "    # initialize the variance and the number of images\n",
        "    var = torch.tensor(0.0, device=device)\n",
        "    n_images = torch.tensor(0, device=device)\n",
        "\n",
        "    # iterate over each class folder\n",
        "    for sub_dir_name in os.listdir(folder_path):\n",
        "\n",
        "        # current sub directory\n",
        "        curr_sub_dir = os.path.join(folder_path, sub_dir_name)\n",
        "\n",
        "        # add to samples each tuple for the current class\n",
        "        for file_name in os.listdir(curr_sub_dir):\n",
        "\n",
        "            if file_name.endswith(\".tiff\"):\n",
        "\n",
        "                # load the current image\n",
        "                image = load_image(os.path.join(curr_sub_dir, file_name))\n",
        "\n",
        "                # apply some other requested transformations\n",
        "                transformations = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "                image = transformations(image).to(device)\n",
        "\n",
        "                # update variance and counter\n",
        "                var += ((image - mean) ** 2).mean()\n",
        "                n_images += 1\n",
        "\n",
        "    # return the std over all images in the dataset\n",
        "    return torch.sqrt(var / n_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s8unVYlZVYa"
      },
      "source": [
        "# Construct training set and validation set from training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwJPmT1ZZVYb"
      },
      "source": [
        "Class for creating a dataset object to correctly store and process images in the training folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GvdUEWV_ZVYb"
      },
      "outputs": [],
      "source": [
        "# number of images per class to be contained in the validation set\n",
        "VAL_IMAGES = 20\n",
        "\n",
        "# class to construct a dataset from existing files\n",
        "class WoodDataset(Dataset):\n",
        "\n",
        "    # Constructor.\n",
        "    # root_dir: directory containing the subfolders (one for each class) with training images.\n",
        "    # transformations: transformations to be applied to images in the dataset.\n",
        "    # train: boolean variable that must be set to True if the user wants to create the\n",
        "    #        training set from given images; False to create the validation set.\n",
        "    def __init__(self, root_dir, transformations=None, train=True):\n",
        "\n",
        "        # device\n",
        "        self.device = \"cpu\"\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = \"cuda\"\n",
        "\n",
        "        # boolean variable specifying whether the training set or the validation\n",
        "        # set has to be created\n",
        "        self.train = train\n",
        "\n",
        "        # images per class to be placed in the validation set\n",
        "        self.n_test_per_class = VAL_IMAGES\n",
        "\n",
        "        # root directory\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "        # classes names and indices\n",
        "        self.classes_labels = self.get_classes_labels()\n",
        "\n",
        "        # (image_path, class_id) for each image the dataset\n",
        "        self.items = self.get_samples()\n",
        "\n",
        "        # transformations to be applied to samples in the dataset\n",
        "        self.transform = transformations\n",
        "\n",
        "\n",
        "    # number of items in the training set\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "\n",
        "    # Retrieves the tuple (image, label) for the image at position index in self.items.\n",
        "    # index: position of the sample to be retrieved from self.items.\n",
        "    # Returns (image, label), where image is the tensor representation for the image to retrieve and\n",
        "    # label is its class index.\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # extract path and class for the image at position index in the dataset\n",
        "        path, label_id = self.items[index]\n",
        "\n",
        "        # load the image using PIL\n",
        "        image = self.load_image(path)\n",
        "\n",
        "        # apply other requested transformations, if any\n",
        "        if self.transform:\n",
        "            image = self.transform(image).to(self.device)\n",
        "\n",
        "        return image, label_id\n",
        "\n",
        "\n",
        "    # creates a dictionary where each class folder name is a key and each value is an integer id\n",
        "    def get_classes_labels(self):\n",
        "\n",
        "        # dictionary that will contain folders names and indices\n",
        "        classes = {}\n",
        "\n",
        "        # names of the class labels\n",
        "        classes_names = [\"UNK\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\"]\n",
        "\n",
        "        # extract class names and assign an index to each of them\n",
        "        for sub_dir in os.scandir(self.root_dir):\n",
        "\n",
        "            # consider only directories\n",
        "            if sub_dir.is_dir():\n",
        "\n",
        "                # extract the name of the directory\n",
        "                class_name = sub_dir.name\n",
        "\n",
        "                # assign an id to each folder name, based on classes_names\n",
        "                for i in range(len(classes_names)):\n",
        "                    if classes_names[i] in class_name:\n",
        "                        classes[class_name] = i\n",
        "\n",
        "        return classes\n",
        "\n",
        "\n",
        "    # loads the samples contained in the dataset as tuples (path_to_image, label)\n",
        "    def get_samples(self):\n",
        "\n",
        "        # list that will contain the tuples\n",
        "        samples = []\n",
        "\n",
        "        # iterate over each class folder\n",
        "        for sub_dir_name in self.classes_labels.keys():\n",
        "\n",
        "            # samples for the current class\n",
        "            curr_samples = []\n",
        "\n",
        "            # id of the current class\n",
        "            class_id = self.classes_labels[sub_dir_name]\n",
        "\n",
        "            # path to the directory where images of the current class are stored\n",
        "            curr_class_dir = os.path.join(self.root_dir, sub_dir_name)\n",
        "\n",
        "            # add to curr_samples each tuple for the current class\n",
        "            for file_name in os.listdir(curr_class_dir):\n",
        "                if file_name.endswith(\".tiff\"):\n",
        "                    curr_samples.append((os.path.join(curr_class_dir, file_name), class_id))\n",
        "\n",
        "            # if we need to construct the training set, add all images but the test ones\n",
        "            if self.train:\n",
        "                curr_samples = curr_samples[:-self.n_test_per_class]\n",
        "\n",
        "            # else, add only test images\n",
        "            else:\n",
        "                curr_samples = curr_samples[-self.n_test_per_class:]\n",
        "\n",
        "            # append to samples elements in curr_samples\n",
        "            for sample in curr_samples:\n",
        "                samples.append(sample)\n",
        "\n",
        "        return samples\n",
        "\n",
        "\n",
        "    # Loads a .tiff image using PIL.\n",
        "    # image_path: path to the image to be loaded.\n",
        "    # Returns the loaded image with mode \"L\".\n",
        "    def load_image(self, image_path):\n",
        "\n",
        "        # load the image with PIL\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # convert it into a numpy array\n",
        "        image_np = np.array(image)\n",
        "\n",
        "        # max pixel value\n",
        "        max_val = np.max(image_np)\n",
        "\n",
        "        # new desired max value\n",
        "        new_max_val = 255\n",
        "\n",
        "        # normalize the pixels and convert their values into unsigned integers\n",
        "        normalized_image = (image_np / max_val * new_max_val).astype(np.uint8)\n",
        "\n",
        "        # return the greyscale image represented by the numpy array\n",
        "        return Image.fromarray(normalized_image, mode=\"L\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkPQRZs_SLia"
      },
      "source": [
        "Define paths and transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c_Zs3IgoZVYb"
      },
      "outputs": [],
      "source": [
        "# path to the training folder\n",
        "training_set_folder = os.path.join(os.getcwd(), \"TRAINING\")\n",
        "\n",
        "# compute mean and std of images in the training folder\n",
        "mean = compute_mean(os.path.join(os.getcwd(), \"TRAINING\"), device)\n",
        "std = compute_std(os.path.join(os.getcwd(), \"TRAINING\"), mean, device)\n",
        "\n",
        "# transformations to be applied to each image in the training folder\n",
        "transformations = transforms.Compose([\n",
        "                           transforms.Resize((224, 224)),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=[mean], std=[std])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_GYAhOISRBd"
      },
      "source": [
        "Load training set and validation set with corresponding dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Pf4RDCwmZM8h"
      },
      "outputs": [],
      "source": [
        "# create a training set with 180 images per class\n",
        "training_set = WoodDataset(root_dir=training_set_folder, transformations=transformations, train=True)\n",
        "\n",
        "# create a validation set with the remaining 20 images per class\n",
        "validation_set = WoodDataset(root_dir=training_set_folder, transformations=transformations, train=False)\n",
        "\n",
        "# create a dataloader to wrap the training set\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# create a dataloader to wrap the validation set\n",
        "batch_size = 64\n",
        "val_dataloader = DataLoader(validation_set, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuRLMThvZVYc"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkzSf7XEZVYc"
      },
      "source": [
        "Load a pre-trained model and modify it according to our needs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak16NzB8e7oF",
        "outputId": "123cfc36-66ca-42b2-ab1f-6b58c9735445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 144MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\Original model:\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "Modified model:\n",
            "ResNet(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# load pre-trained ResNet50\n",
        "resnet_model = models.resnet50(weights=\"ResNet50_Weights.DEFAULT\")\n",
        "\n",
        "# print the original architecture of resnet50 model\n",
        "print(f\"\\Original model:\\n{resnet_model}\\n\\n\")\n",
        "\n",
        "# modify the input layer to be able to feed the model with greyscale images\n",
        "resnet_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# modify the output layer to fit with our number of classes\n",
        "n_classes = 7\n",
        "resnet_model.fc = nn.Linear(in_features=resnet_model.fc.in_features, out_features=n_classes, bias=True)\n",
        "\n",
        "# print the modified version of the model\n",
        "print(f\"\\nModified model:\\n{resnet_model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtwBu8gqOCjf"
      },
      "source": [
        "Function to print statistics on the validation set during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tl_jUDG8OHXG"
      },
      "outputs": [],
      "source": [
        "# Function to print accuracy and average loss on the validation set.\n",
        "# val_dataloader: dataloader containing the validation set.\n",
        "# model: model to test.\n",
        "# loss_function: loss function to be used.\n",
        "# Prints accuracy and average loss in the validation set.\n",
        "def val_model(val_dataloader, model, loss_function):\n",
        "\n",
        "    # number of batches in the dataloader\n",
        "    num_batches = len(val_dataloader)\n",
        "\n",
        "    # set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # cumulative value of the loss function for the entire validation set\n",
        "    val_set_loss = 0\n",
        "\n",
        "    # number of correctly classified samples\n",
        "    correct = 0\n",
        "\n",
        "    # ensure that no gradient is computed\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # iterate through the batches\n",
        "        for batch, labels in val_dataloader:\n",
        "\n",
        "            # move batch and labels to the device\n",
        "            batch = batch.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # make predictions on the current batch\n",
        "            predicted_labels = model(batch)\n",
        "\n",
        "            # update the validation set loss by summing the loss for the current batch\n",
        "            val_set_loss += loss_function(predicted_labels, labels).item()\n",
        "\n",
        "            # update the number of correctly classified samples by adding those for the current batch\n",
        "            correct += (predicted_labels.argmax(-1) == labels).to(device).sum().item()\n",
        "\n",
        "    # compute the mean loss on the validation set by normalizing the sum of losses by the number of batches\n",
        "    val_set_loss /= num_batches\n",
        "\n",
        "    # compute accuracy on the validation set by dividing by the number of samples in the dataset\n",
        "    accuracy = correct / len(val_dataloader.dataset) * 100\n",
        "\n",
        "    # print test set average loss and accuracy\n",
        "    print(f\"Validation Set | Cross Entropy Loss: {val_set_loss: .3f} | Accuracy: {accuracy: .2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vazk_pspjB9N"
      },
      "source": [
        "Function for a training iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1QTj-EBJlM7f"
      },
      "outputs": [],
      "source": [
        "# Function that trains a model for a single iteration.\n",
        "# dataloader: dataloader that contains the training set where to train the model.\n",
        "# model: model to train on dataloader.dataset.\n",
        "# loss_function: loss function that we want to optimize.\n",
        "# optimizer: algorithm to be used to train the model.\n",
        "# lr_sched: learning rate scheduler for updating the learning rate during training.\n",
        "def train_model(dataloader, model, loss_function, optimizer, lr_sched=None):\n",
        "\n",
        "    # turn the model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # initialize the sum of the losses for all batches\n",
        "    total_loss = 0\n",
        "\n",
        "    # initialize the number of correctly predicted labels\n",
        "    correct_labels = 0\n",
        "\n",
        "    # extract a batch at the time\n",
        "    for batch, true_labels in dataloader:\n",
        "\n",
        "        # move to the device both the current batch and its labels\n",
        "        batch = batch.to(device)\n",
        "        true_labels = true_labels.to(device)\n",
        "\n",
        "        # set to 0 the gradient w.r.t. each parameter of the model\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass on the current batch, i.e., output of the model for the current batch\n",
        "        predicted_labels = model(batch)\n",
        "\n",
        "        # value of the loss function for the computed predictions\n",
        "        error = loss_function(predicted_labels, true_labels)\n",
        "\n",
        "        # compute the gradient of the loss w.r.t. model's parameters\n",
        "        error.backward()\n",
        "\n",
        "        # update the model's parameters according to the computed gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        # update the learning rate\n",
        "        if lr_sched:\n",
        "            lr_sched.step()\n",
        "\n",
        "        # update the total loss after the computed predictions\n",
        "        total_loss += error.item()\n",
        "\n",
        "        # update the number of correctly updated labels\n",
        "        _, predicted_classes = torch.max(predicted_labels, -1)\n",
        "        correct_labels += (predicted_classes == true_labels).to(device).sum().item()\n",
        "\n",
        "    # compute mean loss and accuracy\n",
        "    mean_loss = total_loss / len(dataloader)\n",
        "    accuracy = correct_labels / dataloader.dataset.__len__() * 100\n",
        "\n",
        "    # print some some information, including the current loss value, for the training epoch just performed\n",
        "    print(f\"Training Set   | Cross Entropy Loss: {mean_loss: .3f} | Accuracy: {accuracy: .2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWVOJ4aBQKob"
      },
      "source": [
        "Function to train and evaluate a model for a given number of training epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fkoTudBHQRBh"
      },
      "outputs": [],
      "source": [
        "# Function to train a model for a given number of epochs on the given dataloader.\n",
        "# train_dataloader: dataloader containing the training set to be used to update the\n",
        "#                   model's parameters.\n",
        "# val_dataloader: dataloader containing the validation set to be used to print some\n",
        "#                 statistics at each iteration on unseen data.\n",
        "# model: model to be trained.\n",
        "# loss_function: loss function to be optimized.\n",
        "# optimizer: algorithm to be used to update model's parameters.\n",
        "# lr_sched: learning rate scheduler for updating the learning rate during training.\n",
        "# epochs: number of training iterations.\n",
        "def train_loop(train_dataloader, val_dataloader, model, loss_function, optimizer, lr_sched=None, epochs=10):\n",
        "\n",
        "    # train the model for the desired number of epochs\n",
        "    for i in range(epochs):\n",
        "\n",
        "        # print current epoch\n",
        "        print(f\"\\nIteration {i}\")\n",
        "\n",
        "        # train the model on the training set and print some information\n",
        "        train_model(train_dataloader, model, loss_function, optimizer, lr_sched)\n",
        "\n",
        "        # print accuracy and mean loss on the validation set\n",
        "        val_model(val_dataloader, model, loss_function)\n",
        "\n",
        "    # print that training is finished\n",
        "    print(f\"\\n\\nTraining is finished.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sT5xlTA0_Dr"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pPjT7j608nN",
        "outputId": "dfe60105-7ec6-4265-c64a-537f6628a9a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 0\n",
            "Training Set   | Cross Entropy Loss:  1.925 | Accuracy:  17.78%\n",
            "Validation Set | Cross Entropy Loss:  1.979 | Accuracy:  20.71%\n",
            "\n",
            "Iteration 1\n",
            "Training Set   | Cross Entropy Loss:  1.830 | Accuracy:  31.19%\n",
            "Validation Set | Cross Entropy Loss:  2.035 | Accuracy:  15.71%\n",
            "\n",
            "Iteration 2\n",
            "Training Set   | Cross Entropy Loss:  1.819 | Accuracy:  29.21%\n",
            "Validation Set | Cross Entropy Loss:  1.967 | Accuracy:  19.29%\n",
            "\n",
            "Iteration 3\n",
            "Training Set   | Cross Entropy Loss:  1.707 | Accuracy:  36.27%\n",
            "Validation Set | Cross Entropy Loss:  1.852 | Accuracy:  35.00%\n",
            "\n",
            "Iteration 4\n",
            "Training Set   | Cross Entropy Loss:  1.621 | Accuracy:  42.70%\n",
            "Validation Set | Cross Entropy Loss:  1.746 | Accuracy:  31.43%\n",
            "\n",
            "\n",
            "Training is finished.\n",
            "\n",
            "\n",
            "Iteration 0\n",
            "Training Set   | Cross Entropy Loss:  1.135 | Accuracy:  56.19%\n",
            "Validation Set | Cross Entropy Loss:  1.401 | Accuracy:  48.57%\n",
            "\n",
            "Iteration 1\n",
            "Training Set   | Cross Entropy Loss:  0.714 | Accuracy:  73.41%\n",
            "Validation Set | Cross Entropy Loss:  1.195 | Accuracy:  62.14%\n",
            "\n",
            "Iteration 2\n",
            "Training Set   | Cross Entropy Loss:  0.421 | Accuracy:  84.21%\n",
            "Validation Set | Cross Entropy Loss:  0.491 | Accuracy:  81.43%\n",
            "\n",
            "Iteration 3\n",
            "Training Set   | Cross Entropy Loss:  0.245 | Accuracy:  90.79%\n",
            "Validation Set | Cross Entropy Loss:  1.781 | Accuracy:  58.57%\n",
            "\n",
            "Iteration 4\n",
            "Training Set   | Cross Entropy Loss:  0.228 | Accuracy:  91.98%\n",
            "Validation Set | Cross Entropy Loss:  1.410 | Accuracy:  60.71%\n",
            "\n",
            "Iteration 5\n",
            "Training Set   | Cross Entropy Loss:  0.189 | Accuracy:  93.57%\n",
            "Validation Set | Cross Entropy Loss:  0.440 | Accuracy:  87.14%\n",
            "\n",
            "Iteration 6\n",
            "Training Set   | Cross Entropy Loss:  0.115 | Accuracy:  96.03%\n",
            "Validation Set | Cross Entropy Loss:  0.791 | Accuracy:  77.14%\n",
            "\n",
            "Iteration 7\n",
            "Training Set   | Cross Entropy Loss:  0.157 | Accuracy:  94.92%\n",
            "Validation Set | Cross Entropy Loss:  0.270 | Accuracy:  87.86%\n",
            "\n",
            "Iteration 8\n",
            "Training Set   | Cross Entropy Loss:  0.065 | Accuracy:  98.17%\n",
            "Validation Set | Cross Entropy Loss:  0.305 | Accuracy:  90.71%\n",
            "\n",
            "Iteration 9\n",
            "Training Set   | Cross Entropy Loss:  0.062 | Accuracy:  97.70%\n",
            "Validation Set | Cross Entropy Loss:  0.360 | Accuracy:  89.29%\n",
            "\n",
            "Iteration 10\n",
            "Training Set   | Cross Entropy Loss:  0.102 | Accuracy:  96.43%\n",
            "Validation Set | Cross Entropy Loss:  0.519 | Accuracy:  82.14%\n",
            "\n",
            "Iteration 11\n",
            "Training Set   | Cross Entropy Loss:  0.115 | Accuracy:  95.79%\n",
            "Validation Set | Cross Entropy Loss:  0.432 | Accuracy:  82.14%\n",
            "\n",
            "Iteration 12\n",
            "Training Set   | Cross Entropy Loss:  0.086 | Accuracy:  97.14%\n",
            "Validation Set | Cross Entropy Loss:  0.238 | Accuracy:  92.86%\n",
            "\n",
            "Iteration 13\n",
            "Training Set   | Cross Entropy Loss:  0.053 | Accuracy:  98.25%\n",
            "Validation Set | Cross Entropy Loss:  0.278 | Accuracy:  90.00%\n",
            "\n",
            "Iteration 14\n",
            "Training Set   | Cross Entropy Loss:  0.037 | Accuracy:  99.13%\n",
            "Validation Set | Cross Entropy Loss:  0.482 | Accuracy:  83.57%\n",
            "\n",
            "Iteration 15\n",
            "Training Set   | Cross Entropy Loss:  0.024 | Accuracy:  99.21%\n",
            "Validation Set | Cross Entropy Loss:  0.345 | Accuracy:  92.14%\n",
            "\n",
            "Iteration 16\n",
            "Training Set   | Cross Entropy Loss:  0.026 | Accuracy:  99.52%\n",
            "Validation Set | Cross Entropy Loss:  0.200 | Accuracy:  91.43%\n",
            "\n",
            "Iteration 17\n",
            "Training Set   | Cross Entropy Loss:  0.016 | Accuracy:  99.29%\n",
            "Validation Set | Cross Entropy Loss:  0.570 | Accuracy:  89.29%\n",
            "\n",
            "Iteration 18\n",
            "Training Set   | Cross Entropy Loss:  0.031 | Accuracy:  98.89%\n",
            "Validation Set | Cross Entropy Loss:  0.480 | Accuracy:  90.00%\n",
            "\n",
            "Iteration 19\n",
            "Training Set   | Cross Entropy Loss:  0.016 | Accuracy:  99.68%\n",
            "Validation Set | Cross Entropy Loss:  0.161 | Accuracy:  93.57%\n",
            "\n",
            "Iteration 20\n",
            "Training Set   | Cross Entropy Loss:  0.007 | Accuracy:  99.76%\n",
            "Validation Set | Cross Entropy Loss:  0.113 | Accuracy:  92.86%\n",
            "\n",
            "Iteration 21\n",
            "Training Set   | Cross Entropy Loss:  0.002 | Accuracy:  100.00%\n",
            "Validation Set | Cross Entropy Loss:  0.199 | Accuracy:  92.86%\n",
            "\n",
            "Iteration 22\n",
            "Training Set   | Cross Entropy Loss:  0.004 | Accuracy:  99.76%\n",
            "Validation Set | Cross Entropy Loss:  0.249 | Accuracy:  92.86%\n",
            "\n",
            "Iteration 23\n",
            "Training Set   | Cross Entropy Loss:  0.004 | Accuracy:  99.92%\n",
            "Validation Set | Cross Entropy Loss:  0.206 | Accuracy:  92.86%\n",
            "\n",
            "Iteration 24\n",
            "Training Set   | Cross Entropy Loss:  0.001 | Accuracy:  100.00%\n",
            "Validation Set | Cross Entropy Loss:  0.126 | Accuracy:  95.71%\n",
            "\n",
            "Iteration 25\n",
            "Training Set   | Cross Entropy Loss:  0.000 | Accuracy:  100.00%\n",
            "Validation Set | Cross Entropy Loss:  0.096 | Accuracy:  95.00%\n",
            "\n",
            "Iteration 26\n",
            "Training Set   | Cross Entropy Loss:  0.000 | Accuracy:  100.00%\n",
            "Validation Set | Cross Entropy Loss:  0.085 | Accuracy:  95.00%\n",
            "\n",
            "Iteration 27\n",
            "Training Set   | Cross Entropy Loss:  0.000 | Accuracy:  100.00%\n",
            "Validation Set | Cross Entropy Loss:  0.158 | Accuracy:  95.00%\n",
            "\n",
            "Iteration 28\n",
            "Training Set   | Cross Entropy Loss:  0.000 | Accuracy:  100.00%\n",
            "Validation Set | Cross Entropy Loss:  0.135 | Accuracy:  95.00%\n",
            "\n",
            "Iteration 29\n",
            "Training Set   | Cross Entropy Loss:  0.000 | Accuracy:  100.00%\n",
            "Validation Set | Cross Entropy Loss:  0.248 | Accuracy:  95.00%\n",
            "\n",
            "\n",
            "Training is finished.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# hyperparameters\n",
        "learning_rate = 1e-3\n",
        "regularization = 2e-05\n",
        "\n",
        "# move the model to the device\n",
        "resnet_model.to(device)\n",
        "\n",
        "# use cross entropy as loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# INITIALIZE WEIGHTS OF NEW ADDED LAYERS WITH SOME ITERATIONS\n",
        "\n",
        "# at the beginning, we allow the optimizer to update only parameters of the new layers\n",
        "parameters_to_update = [\n",
        "    {\"params\": resnet_model.conv1.parameters(), \"lr\": learning_rate},\n",
        "    {\"params\": resnet_model.fc.parameters(), \"lr\": learning_rate}\n",
        "]\n",
        "\n",
        "# use Adam as optimizer\n",
        "optimizer = optim.Adam(parameters_to_update, weight_decay=regularization)\n",
        "\n",
        "# number of epochs\n",
        "epochs = 5\n",
        "\n",
        "# train the model for the desired number of epochs\n",
        "train_loop(train_dataloader, val_dataloader, resnet_model, loss_function, optimizer, epochs=epochs)\n",
        "\n",
        "# FINE-TUNE THE MODEL BY UPDATING ALL WEIGHTS\n",
        "\n",
        "# use Adam as optimizer as before\n",
        "optimizer = optim.Adam(resnet_model.parameters(), lr=learning_rate, weight_decay=regularization)\n",
        "\n",
        "# number of epochs\n",
        "epochs = 30\n",
        "\n",
        "# train the model for the desired number of epochs\n",
        "train_loop(train_dataloader, val_dataloader, resnet_model, loss_function, optimizer, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvjYeFqXchzx"
      },
      "source": [
        "# Save the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6eLq5oV5ck7C"
      },
      "outputs": [],
      "source": [
        "# save the state dict with learnt weights and not the entire model\n",
        "torch.save(resnet_model.state_dict(), \"weights_30.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "03-7YfO3bDAy",
        "7s8unVYlZVYa"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}